# LSDobserve
lsdobserve:
  # There are your options:
  # openshift
  # gke
  # rancher
  clusterType: openshift
  # adminUsername is the general username to configure for all tools, so each tool uses the same username
  adminUsername: "lsdobserve"
  # adminPsername is the general password to configure for all tools, so each tool uses the same password
  adminPassword: "password4lsdobserve"
  # the domain to use as a suffix for all ingress traffic. Example grafana-lsd-observe.$domain
  domain: apps.lsdopen.io
  smtp:
    host: "smtp.lsdopen.io"
    port: "25"
    username: "XXXXX"
    password: "XXXXX"
    fromAddress: "lsdobserve+noreply+FULL-CLUSTER-NAME@lsdopen.io"
    fromName: "LSDobserve - CLIENT - FULL-CLUSTER-NAME"
  letsencrypt: false
  # letsencrypt-staging for staging
  # letsencrypt for production
  letsencryptIssuer: letsencrypt-staging
  grafana:
    enabled: true
    ingress:
      url: grafana.apps.cluster-01.lsdopen.io
  elastic:
    enabled: true
    count: "3"
    storage: "50Gi"
    storageClassName: "rook-ceph-block"
    filebeat:
      enabled: true
    apm:
      enabled: true
    kibana:
      enabled: true
      count: "2"
      ingress:
        url: kibana.apps.cluster-01.lsdopen.io

# Prometheus
# To get a latest values you can run:
# helm show values prometheus-community/prometheus
prometheus:
  server:
    replicaCount: 2
    statefulSet:
      enabled: true
    ingress:
      enabled: true
      hosts:
        - prometheus.apps.cluster-01.lsdopen.io
    persistentVolume:
      enabled: true
      accessModes:
        - ReadWriteOnce
      size: 30Gi
    resources: 
      limits:
        cpu: 500m
        memory: 2Gi
      requests:
        cpu: 100m
        memory: 512Mi
  pushgateway:
    enabled: false
  nodeExporter:
    enabled: true
    hostNetwork: true
    hostPID: true
    name: node-exporter
    pod:
      labels:
        org: lsd
        product: lsdobserve
        name: node-exporter
    resources:
      limits:
        cpu: 200m
        memory: 50Mi
      requests:
        cpu: 100m
        memory: 10Mi
    securityContext: {}
      # runAsUser: 0
    service:
      annotations:
        prometheus.io/scrape: "true"
      labels: {}
      clusterIP: None
      externalIPs: []
      hostPort: 8100
      loadBalancerIP: ""
      loadBalancerSourceRanges: []
      servicePort: 8100
      type: ClusterIP
    tolerations: 
      - key: "node-role.kubernetes.io/controlplane"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "node-role.kubernetes.io/etcd"
        operator: "Exists"
        effect: "NoExecute"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
        effect: "NoExecute"
  alertmanager:
    replicaCount: 3
    statefulSet:
      enabled: true
    image:
      repository: prom/alertmanager
    ingress:
      enabled: true
      hosts:
        - alertmanager.apps.cluster-01.lsdopen.io
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 10m
        memory: 32Mi
    persistentVolume:
      enabled: true
      accessModes:
        - ReadWriteOnce
      size: 1Gi
  alertmanagerFiles:
    alertmanager.yml:
      global:
        resolve_timeout: 5m
      receivers:
        - name: LSD Support
          email_configs:
            - to: support+discoverybank@lsd.co.za
              from: lsdobserve+noreply+FULL-CLUSTER-NAME@lsdopen.io
              smarthost: 'smtp.lsdopen.io:25'
              require_tls: false
      route:
        group_by:
          - job
        group_interval: 5m
        group_wait: 30s
        receiver: 'LSD Support'
        repeat_interval: 12h
        routes:
          - receiver: LSD Support
            match:
              severity: warning
          - receiver: LSD Support
            match:
              severity: critical
  serverFiles:
    alerting_rules.yml:
      groups:
      - name: Instances
        rules:
          - alert: InstanceDown
            expr: up == 0
            for: 5m
            labels:
              severity: warning
            annotations:
              description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'
              summary: 'Instance {{ $labels.instance }} down'
      - name: NodesMarkedAsUnscheduled
        rules:
          - alert: NodesMarkedAsUnscheduled
            expr: kube_node_spec_unschedulable > 0
            for: 1m
            labels:
              severity: warning
            annotations:
              description: '{{ $labels.kubernetes_node }} is marked as Unscheduled for longer than 5 minutes.'
              summary: 'Instance {{ $labels.kubernetes_node }} marked as Unscheduled'

# Elasticsearch Exporter
# To get a latest values you can run:
# helm show values prometheus-community/prometheus-elasticsearch-exporter
prometheus-elasticsearch-exporter:
  replicaCount: 1

# Elasticsearch Exporter
# To get a latest values you can run:
# helm show values elastic/eck-operator
eck-operator:
  replicaCount: 1
  installCRDs: true
  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 20m
      memory: 150Mi

# Grafana
# To get a latest values you can run:
# helm show values grafana/grafana
grafana:
  adminUser: admin
  adminPassword: pho0iar5zo2oob8geevohd0ahr4hieNi
  replicas: 1
  # ingress is disable because it is created via the lsd-observe template
  ingress:
    enabled: false
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: LSDobserve - Prometheus
        type: prometheus
        url: http://lsdobserve-prometheus-server
        isDefault: true
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'ds-01'
        orgId: 1
        folder: 'LSDobserve'
        type: file
        disableDeletion: false
        editable: false
        options:
          path: /var/lib/grafana/dashboards/ds-01
  dashboardsConfigMaps:
    ds-01: "grafana-dashboard-kubernetes-overview"
    ds-02: "grafana-dashboard-namespace-details"
    ds-03: "grafana-dashboard-node-namespace-details"
    ds-04: "grafana-dashboard-apiserver"
    ds-05: "grafana-dashboard-rook-ceph-overview"
    ds-06: "node-exporter-for-prometheus-dashboard"
  imageRenderer:
    enabled: true
    replicas: 1
    image:
      repository: grafana/grafana-image-renderer
      tag: latest
    service:
      portName: 'http'
      port: 8081
    podPortName: http
    revisionHistoryLimit: 10
    networkPolicy:
      limitIngress: true
      limitEgress: false
    resources:
     limits:
       cpu: 100m
       memory: 100Mi
     requests:
       cpu: 50m
       memory: 50Mi
